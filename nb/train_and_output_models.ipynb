{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-4B2O8LeSAb",
        "outputId": "7b5aa2ed-81de-473c-a8f1-855474f7b5b6"
      },
      "id": "g-4B2O8LeSAb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/fourthbrain-capstone/nlp4ifchallenge/'\n",
        "import sys\n",
        "sys.path.append(root)"
      ],
      "metadata": {
        "id": "StJtU5XefAtV"
      },
      "id": "StJtU5XefAtV",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "C6u8ZZ3L23iO"
      },
      "id": "C6u8ZZ3L23iO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6aa3e7b8",
      "metadata": {
        "id": "6aa3e7b8"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Callable, TypeVar, Any, overload, Dict\n",
        "from typing import Optional as Maybe\n",
        "\n",
        "import torch\n",
        "from torch import Tensor, LongTensor\n",
        "from torch import load, cat, stack, save, no_grad, manual_seed\n",
        "from torch.cuda import empty_cache\n",
        "\n",
        "from nlp4ifchallenge import types\n",
        "from nlp4ifchallenge.scripts import train_bert, train_aggregator\n",
        "from nlp4ifchallenge.models import bert, aggregation\n",
        "\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity(\"CRITICAL\")\n",
        "\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example tweet: this tweet should be classified as contained misinfo\n",
        "tweets = [types.Tweet(0, \"President Trump's comments about the coronavirus death rate were 100% correct. The media falsely claimed he was spreading misinformation. They falsely reported that his comments weren't in line with top health officials. That was 100% fake news.\")]"
      ],
      "metadata": {
        "id": "WjQb6UchAx3z"
      },
      "id": "WjQb6UchAx3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrain 8 individual Bert models, save them in checkpoints"
      ],
      "metadata": {
        "id": "WURr-rPDAo3L"
      },
      "id": "WURr-rPDAo3L"
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['vinai-covid', 'vinai-tweet', 'cardiffnlp-tweet', 'cardiffnlp-hate', 'del-covid', 'cardiffnlp-irony', 'cardiffnlp-offensive', 'cardiffnlp-emotion']\n",
        "device = \"cuda\"\n",
        "train_path = root+'data/english/covid19_disinfo_binary_english_train_old.tsv'\n",
        "dev_path = root+'data/english/covid19_disinfo_binary_english_dev_input.tsv'\n",
        "test_path = \"\"\n",
        "batch_size = 16\n",
        "early_stopping = 0\n",
        "num_epochs = 3\n",
        "save_path = root+'data/checkpoints'\n",
        "with_class_weights = False\n",
        "ignore_nan = False\n",
        "\n",
        "for name in names:\n",
        "  train_bert.main(name=name, device=device, print_log=True, train_path=train_path,\n",
        "                dev_path=dev_path, test_path=test_path, batch_size=batch_size, early_stopping=early_stopping,\n",
        "                num_epochs=num_epochs, save_path=save_path,\n",
        "                with_class_weights=with_class_weights, ignore_nan=ignore_nan)"
      ],
      "metadata": {
        "id": "lcpxwQWCT5eh"
      },
      "id": "lcpxwQWCT5eh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with test example"
      ],
      "metadata": {
        "id": "j_dORYHaAuTb"
      },
      "id": "j_dORYHaAuTb"
    },
    {
      "cell_type": "code",
      "source": [
        "for name in names:\n",
        "  model = bert.make_model(name=name, ignore_nan=ignore_nan)\n",
        "  # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  checkpoint = torch.load(root+'data/checkpoints/'+name+'-english/model.p', map_location=torch.device(device))\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  # epoch = checkpoint['epoch']\n",
        "  # loss = checkpoint['loss']\n",
        "  model.eval()\n",
        "  print(name, model.predict(tweets))"
      ],
      "metadata": {
        "id": "nqvva4cK2wH3"
      },
      "id": "nqvva4cK2wH3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrain ensemble Bert Model: version containing all 8 individual Bert models"
      ],
      "metadata": {
        "id": "YEGNExYIA-M4"
      },
      "id": "YEGNExYIA-M4"
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = str(len(names))\n",
        "train_path = root+'data/english/covid19_disinfo_binary_english_train_old.tsv'\n",
        "dev_path = root+'data/english/covid19_disinfo_binary_english_dev_input.tsv'\n",
        "test_path = \"\"\n",
        "device = \"cuda\"\n",
        "batch_size = 16\n",
        "dropout = 0.25\n",
        "num_epochs = 3\n",
        "model_dir = root+'data/checkpoints'\n",
        "hidden_size = 12\n",
        "lr = 1e-02\n",
        "wd = 1e-02\n",
        "load_stored = False\n",
        "\n",
        "train_aggregator.main(model_names=model_names,\n",
        "               train_path=train_path, dev_path=dev_path, test_path=test_path,\n",
        "               device=device, batch_size=batch_size, dropout=dropout, \n",
        "               num_epochs=num_epochs, model_dir=model_dir,\n",
        "               hidden_size=hidden_size, lr=lr, wd=wd, load_stored=load_stored,\n",
        "               print_log=True)"
      ],
      "metadata": {
        "id": "-2J2tAxk08fM"
      },
      "id": "-2J2tAxk08fM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with test example"
      ],
      "metadata": {
        "id": "lUDaCZWTBOMv"
      },
      "id": "lUDaCZWTBOMv"
    },
    {
      "cell_type": "code",
      "source": [
        "[test_inputs] = train_aggregator.get_scores(model_names=names,\n",
        "                                            datasets=[tweets],\n",
        "                           batch_size=batch_size, device=device,\n",
        "                           model_dir=model_dir, data_tag=\"english\")\n",
        "# votes = train_aggregator.aggregate_votes(test_inputs)\n",
        "# votes\n",
        "aggregator = train_aggregator.MetaClassifier(num_models=8, hidden_size=hidden_size, dropout=dropout).to(device)\n",
        "aggregator.load_state_dict(torch.load(model_dir + f'/aggregator-english/model.p'))\n",
        "outs = aggregator.predict(test_inputs.to(device))\n",
        "outs"
      ],
      "metadata": {
        "id": "08i3kZpE0-1x"
      },
      "id": "08i3kZpE0-1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portion of FastAPI codes: use this to debug API results"
      ],
      "metadata": {
        "id": "iCgftMS2BRyN"
      },
      "id": "iCgftMS2BRyN"
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELS_DIR = root+'data/checkpoints/'\n",
        "# device = \"cpu\"\n",
        "# batch_size = 16\n",
        "# ignore_nan = False\n",
        "# hidden_size = 12\n",
        "# dropout = 0.25\n",
        "\n",
        "# MODELS = {'vinai-covid': None,\n",
        "#           'vinai-tweet': None,\n",
        "#           'cardiffnlp-tweet': None,\n",
        "#           'cardiffnlp-hate': None,\n",
        "#           'del-covid': None,\n",
        "#           'cardiffnlp-irony': None,\n",
        "#           'cardiffnlp-offensive': None,\n",
        "#           'cardiffnlp-emotion': None}\n",
        "\n",
        "# for name in MODELS:\n",
        "#     model = bert.make_model(name=name, ignore_nan=ignore_nan)\n",
        "#     checkpoint = torch.load(MODELS_DIR+name+'-english/model.p', map_location=torch.device(device))\n",
        "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#     model.eval()\n",
        "#     MODELS[name] = model\n",
        "\n",
        "\n",
        "# def get_scores(model_names: List[str], datasets: List[List[types.Tweet]], batch_size: int, device: str,\n",
        "#                model_dir: str, data_tag: str) -> List[Tensor]:\n",
        "#     \"\"\"\n",
        "#        :returns num_dataset tensors of shape B x M x Q\n",
        "#     \"\"\"\n",
        "#     outs = []\n",
        "#     for name in model_names:\n",
        "#         this_model_outs = []\n",
        "#         model = MODELS[name]\n",
        "#         for dataset in datasets:\n",
        "#             this_dataset_outs = []\n",
        "#             nbatches = ceil(len(dataset) / batch_size)\n",
        "#             for batch_idx in range(nbatches):\n",
        "#                 start, end = batch_idx * batch_size, min(len(dataset), (batch_idx + 1) * batch_size)\n",
        "#                 this_dataset_outs.append(model.predict_scores(dataset[start:end]).cpu())\n",
        "#             this_model_outs.append(cat(this_dataset_outs, dim=0))\n",
        "#         outs.append(this_model_outs)\n",
        "#         empty_cache()\n",
        "#     return [stack(x, dim=1) for x in zip(*outs)]\n",
        "\n",
        "\n",
        "# tweets = [\"President Trump's comments about the coronavirus death rate were 100% correct. The media falsely claimed he was spreading misinformation. They falsely reported that his comments weren't in line with top health officials. That was 100% fake news.\"]\n",
        "\n",
        "# ins = []\n",
        "# for i, t in enumerate(tweets):\n",
        "#     ins.append(types.Tweet(i, t))\n",
        "# # ins = [types.Tweet(0, tweets)]\n",
        "\n",
        "# predictions = {}\n",
        "# for name in MODELS:\n",
        "#     model = MODELS[name]\n",
        "#     predictions[name] = model.predict(ins)\n",
        "\n",
        "# [test_inputs] = get_scores(model_names=MODELS.keys(), datasets=[ins],\n",
        "#                 batch_size=batch_size, device=device, model_dir=MODELS_DIR, data_tag=\"english\")\n",
        "# aggregator = train_aggregator.MetaClassifier(num_models=8, hidden_size=hidden_size, dropout=dropout).to(device)\n",
        "# aggregator.load_state_dict(torch.load(MODELS_DIR+'/aggregator-english/model.p', map_location=torch.device(device)))\n",
        "# predictions['aggregator'] = aggregator.predict(test_inputs.to(device))\n",
        "# predictions"
      ],
      "metadata": {
        "id": "r7vjl6Ku21Uq"
      },
      "id": "r7vjl6Ku21Uq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}